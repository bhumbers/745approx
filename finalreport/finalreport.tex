\documentclass{article}

\usepackage{fullpage}

\begin{document}

\title{Approximating Functions for Grid Domains}
\author{Danny Zhu (dannyz) \and Yuzi Nakamura (ynakamur) \and Ben Humberston (bhumbers)}

\maketitle

\section{Introduction}

Approximate computing is a method of computation that sacrifices accuracy for computation time and energy. For certain problems, a large degree of precision may not be necessary, and the savings gained in battery life or power costs may be worth more than the accuracy lost. In particular, we are inspired by the RoboCup code, where speed in decision-making trades off with the optimality of the final decision. Approximate compilation is a promising way of implementing approximate computation that can be done on current machines.

In this project, we take several C functions and

\section{Related Work}
In tandem with the renewed focus on paralell computing, interest in general purpose approximate computing increased recently in response to the decelerating efficiency gains for traditional scalar microprocessors. Techniques in approximate compilation automatically produce inexact yet more efficient versions of programmer-specified ``approximable'' code regions or data structures. An approximating compiler is thus responsible for encapsulating the low-level implementation of approximated code derived, typically, from high level source. The programmer's input over how the approximation is implemented may only be binary (eg: annotating some functions as ``approximable'', as in \cite{Esmaeilzadeh12}), or they may be given finer-grained control over the tradeoff between accuracy and speedup of the approximation, as in the quality programmable machine instructions from \cite{Venkataramani13}.

\cite{Agarwal09} introduces the SpeedPress compiler and SpeedGuard runtime which make use of an approximate compilation strategy that they term ``code perforation''. This strategy selectively drops iterations from long-lasting loops based on the current value of a user-defined quality metric. It has the advantage of allowing a computation to be dynamically retargeted for either realtime performance or accuracy, a useful property for time-critical systems.

Although our project is restricted to software approximation schemes, our primary motivation comes from \cite{Esmaeilzadeh12}, which presents a framework for offloading C++ function calls suitable for approximation to a programmable neural processing unit (NPU). Akin to graphics processing units (GPUs) used for accelerating raster graphic operations, the NPU is a computational accelerator designed to simulate neural network computations using decreased power and faster execution than is possible using a general purpose CPU. \cite{Amant14} builds on this approach with additional insights on compiling for analog circuit NPUs. The compiler is given a model of the restrictions of analog network computations (limited precision, non-ideal activation functions, and restrictions on network topologies) and generates function-approximating networks accordingly.

An alterative to marking specific code sections or functions as ``approximable'' is to instead label data items as either precise or approximate, as in the ``EnerJ'' extension to Java from \cite{Sampson11}. Users of EnerJ may set annotations for approximate data in a manner similar to constant data qualifiers. The compiler statically enforces restrictions on data flow from approximate to precise containers unless the user explicitly permits it.

\section{Method}

\section{Results}

\bibliographystyle{ieeetr}
\bibliography{sources}

\end{document}